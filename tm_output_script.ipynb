{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "fa345bbc-76fa-497e-8b7a-1639e21ea692",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "from io import StringIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "854cd914-c48c-40f9-9bea-5d5755def1cd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Unncoment interested subject \n",
    "subject = 'publications'\n",
    "subject = 'Horizon'\n",
    "subject = 'EIC'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "364fdbb7-7794-4778-8fcc-605b0ba898d5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if subject == 'publications':\n",
    "    path_original = '/export/data_ml4ds/AI4U/Datasets/ResearchPortal/20231005/parquet_preprocessed/publications.parquet'\n",
    "    path_lem = '/export/data_ml4ds/AI4U/Datasets/ResearchPortal/lemmatized/publications_lemmatized.parquet'\n",
    "\n",
    "    topic_model_folder = 'publications_calls_topicmodels'\n",
    "    topic_model = 'publications_calls_44tpc'\n",
    "    inference_folder = 'publications_inference'\n",
    "    id_col = 'actID'\n",
    "    n_topics = 44\n",
    "    save_path = '/export/usuarios_ml4ds/mbalairon/github/recommendation_system/publications_topics.parquet'\n",
    "    \n",
    "elif subject == 'Horizon':\n",
    "    topic_model_folder = 'publications_calls_topicmodels'\n",
    "    topic_model = 'publications_calls_44tpc'\n",
    "    n_topics = 44\n",
    "    inference_folder = 'horizon_inference' \n",
    "    id_col = 'Call'\n",
    "    path_original = '/export/data_ml4ds/AI4U/Datasets/work_programmes/horizon_work_programmes.parquet'\n",
    "    path_lem = '/export/data_ml4ds/AI4U/Datasets/work_programmes/work_programmes_lematized/horizon_work_programmes_lematized'\n",
    "    save_path = '/export/usuarios_ml4ds/mbalairon/github/recommendation_system/horizon_topics.parquet'\n",
    "\n",
    "elif subject == 'EIC':\n",
    "    topic_model_folder = 'publications_calls_topicmodels'\n",
    "    topic_model = 'publications_calls_44tpc'\n",
    "    n_topics = 44\n",
    "    inference_folder = 'eic_inference' \n",
    "    id_col = 'id'\n",
    "    path_original = '/export/data_ml4ds/AI4U/Datasets/work_programmes/EIC_work_programmes.parquet'\n",
    "    path_lem = '/export/data_ml4ds/AI4U/Datasets/work_programmes/work_programmes_lematized/EIC_work_programmes_lematized'\n",
    "    save_path = '/export/usuarios_ml4ds/mbalairon/github/recommendation_system/eic_topics.parquet'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "de36fbc2-3800-46e6-9a5f-f5a1f438d0a4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# define header of the document topic decomposition\n",
    "head = ['doc', id_col]\n",
    "\n",
    "for i in range (n_topics):\n",
    "    head.append('tpc_' + str(i))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "b8042e49-21a8-4e1d-af8b-60c7584bc025",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load necessary files\n",
    "df_lem = pd.read_parquet(path_lem)\n",
    "inferences = pd.read_csv('/export/usuarios_ml4ds/mbalairon/{}/TMmodels/{}/TMinference/{}/doc-topics-inf.txt'.format(topic_model_folder, topic_model, inference_folder), sep = '\\t', names=head).drop(0, axis=0)\n",
    "tpc_keys = pd.read_csv('/export/usuarios_ml4ds/mbalairon/{}/TMmodels/{}/TMmodel/tpc_labels.txt'.format(topic_model_folder, topic_model), names=['label'])\n",
    "df_original = pd.read_parquet(path_original)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "322973cd-a97a-435a-a5be-5ede1d49d114",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Add a column with a vector containig the complete topic decomposition \n",
    "inferences['tpc_decomposition'] = inferences[['tpc_{}'.format(i) for i in range(n_topics)]].apply(tuple, axis=1)\n",
    "inferences['tpc_decomposition_dict'] = inferences['tpc_decomposition'].apply(lambda tupla: {i: valor for i, valor in enumerate(tupla)})\n",
    "inferences['tpc_decomposition_dict'] = inferences['tpc_decomposition_dict'].apply(lambda d: dict(sorted(d.items(), key=lambda item: item[1], reverse=True)))\n",
    "inferences['tpc_ordered'] = inferences['tpc_decomposition_dict'].apply(lambda d: ', '.join(map(str, d.keys())))\n",
    "inferences['tpc_ordered'] = inferences['tpc_ordered'].apply(lambda indices: ', '.join(tpc_keys['label'][int(idx)] for idx in indices.split(', ')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "f573b405-6441-46da-801a-da000f1ec05f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 4)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inferences[[id_col, 'tpc_decomposition', 'tpc_decomposition_dict', 'tpc_ordered']].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "369f3af7-8a78-400a-9401-470281511352",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 7)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_lem.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "7da1b342-7b18-4331-b257-51e11a4efd59",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.merge(df_lem, inferences[[id_col, 'tpc_decomposition', 'tpc_decomposition_dict', 'tpc_ordered']], on=id_col, how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "237ca420-5eb5-43cf-9dd0-244e3396c467",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if subject == 'publications':\n",
    "    df = pd.merge(df, df_original[[id_col, 'Title']], on='actID', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "395726ff-8b3b-44b5-bfc0-e6869b5f598a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 10)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "a81ec7f3-b0bc-4ea0-8da0-564d6e78843c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df['tpc_decomposition_dict'] = df['tpc_decomposition_dict'].apply(lambda d: {str(k): v for k, v in d.items()} if isinstance(d, dict) else d)\n",
    "df.to_parquet(save_path, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
